{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ca1e2a",
   "metadata": {},
   "source": [
    "<h1>Limpieza de datos</h1>\n",
    "Justificar cada apartado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1871147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar csv de personal population\n",
    "\n",
    "personal_Victimization_Original = pd.read_csv(\"../../data/personal_victimization_mapped.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306255a6",
   "metadata": {},
   "source": [
    "<h3>Enconding de categóricas</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83ebce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "484dab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEPARAR LAS X DE LA Y\n",
    "y = personal_Victimization_Original[\"newoff\"]\n",
    "x = personal_Victimization_Original.drop(columns=[\"newoff\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1ad41a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newoff\n",
       "4    42657\n",
       "3    13250\n",
       "2     7199\n",
       "1     3583\n",
       "5     2163\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39037005",
   "metadata": {},
   "source": [
    "Tenemos 5 posibles valores en Y, y como observamos la cantidad de datos no está proporcionada, por esto a la hora de dividir en Train y Test vamos a usar 'stratify = y'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448a8e37",
   "metadata": {},
   "source": [
    "<h3> Separar los  datos en Train y Test </h3>\n",
    "\n",
    "Se utilizó train test split con una semilla de 42, dejando la misma proporcion de 'y' en test y train y se dividio el conjunto en un 80 para train y 20 para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e292abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5350bb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Datos de entrenamiento: 55081 crimenes (80.0%)\n",
      " Datos de prueba: 13771 crimenes (20.0%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n Datos de entrenamiento: {len(x_train)} crimenes ({len(x_train)/len(personal_Victimization_Original)*100:.1f}%)\")\n",
    "print(f\" Datos de prueba: {len(x_test)} crimenes ({len(x_test)/len(personal_Victimization_Original)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d526c1",
   "metadata": {},
   "source": [
    "<h3>Escalado</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2fd4d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de los datos\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "# Convertir a DataFrame, manteniendo los nombres de las columnas originales\n",
    "x_train_scaled = pd.DataFrame(x_train_scaled, columns=x_train.columns)\n",
    "x_test_scaled = pd.DataFrame(x_test_scaled, columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57013b",
   "metadata": {},
   "source": [
    "<h3>Guardar datos</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c13ede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar x_train, x_test, y_train, y_test en CSV sin escalar para el arbol de desicion y el random forest\n",
    "x_train.to_csv(\"../../data/x_train.csv\", index=False)\n",
    "x_test.to_csv(\"../../data/x_test.csv\", index=False)\n",
    "y_train.to_csv(\"../../data/y_train.csv\", index=False)\n",
    "y_test.to_csv(\"../../data/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a3174885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar x_train, x_test, y_train, y_test en CSV escalados para la regresion logistica y la red neuronal\n",
    "\n",
    "x_train_scaled.to_csv(\"../../data/x_train_scaled.csv\", index=False)\n",
    "x_test_scaled.to_csv(\"../../data/x_test_scaled.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TheFirstOne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
